\documentclass[11pt,a4paper]{article}
\usepackage{bbm,amsthm,amsfonts,amssymb,amsmath,latexsym,epic,eepic}
\usepackage{marvosym,graphicx,fancyhdr,bbm}
\usepackage{graphicx}
\usepackage{gensymb}
\usepackage{url}
\usepackage{color}
\usepackage[rflt]{floatflt}
\usepackage{colortbl}
\usepackage{subcaption}
\usepackage{url}
\usepackage[vlined, ruled, boxed]{algorithm2e}
\definecolor{Grey}{rgb}{0.5,0.5,0.5}
\definecolor{Red}{rgb}{1.0,0.0,0.0}
\renewcommand{\figurename}{Abbildung}
\usepackage{typearea}
\areaset{156mm}{235mm}
%\setlength{\parskip}{5pt plus 2pt minus 1pt}
\setlength{\parindent}{0pt}

% use \M for matrices and \V for vectors in math mode
\newcommand{\M}[1]{\mathbf{#1}}
\newcommand{\V}[1]{\mathbf{#1}}
\newcommand{\norm}[1]{\left | \left | #1 \right | \right |}
\newcommand{\RR}{\mathbbm{R}}        % set of real numbers


\renewcommand\floatpagefraction{0.8}
\renewcommand\topfraction{1}
\renewcommand\bottomfraction{0.9}
\renewcommand\textfraction{0.0}
%\def\dbltopfraction{1.0}
%\def\bottomfraction{1.0}
%\def\dblfloatpagefraction{0.8}


\makeatletter
\renewenvironment{thebibliography}[1]
     {\section*{\refname}%
      \@mkboth{\MakeUppercase\refname}{\MakeUppercase\refname}%
	 \parsep0mm
	 \itemsep0mm
	 %\labelsep0mm
	 %\itemindent0mm
      \list{\@biblabel{\@arabic\c@enumiv}}%
           {\settowidth\labelwidth{\@biblabel{#1}}%
            \leftmargin\labelwidth
            \advance\leftmargin\labelsep
            \@openbib@code
            \usecounter{enumiv}%
            \let\p@enumiv\@empty
            \renewcommand\theenumiv{\@arabic\c@enumiv}}%
      \sloppy
      \clubpenalty4000
      \@clubpenalty \clubpenalty
      \widowpenalty4000%
      \sfcode`\.\@m}
     {\def\@noitemerr
       {\@latex@warning{Empty `thebibliography' environment}}%
      \endlist}
\renewcommand\newblock{\hskip .11em\@plus.33em\@minus.07em}
\let\@openbib@code\@empty
\makeatother



\begin{document}\sloppy

\title{\Large\bf Test von Algorithmen zur Lokalisation, Kartierung und Pfadverfolgung \footnotetext{Diese Arbeit ist Bestandteil des Praktikums zur Mess- und Regelungstechnik}}

\author{Kai Hofmann und Barbara Fischbach\\
  Robotik und Telematik \\
  Universit\"at W\"urzburg\\
  Am Hubland, D-97074 W\"urzburg\\
{\small \texttt{barbara.fischbach@uni-wuerzburg.de}}\\
{\small \texttt{kai.hofmann@uni-wuerzburg.de}}}

\date{}



\maketitle


\newpage

\twocolumn

\section*{Abstract}

\addcontentsline{toc}{section}{Abstract}

\textbf{Die autononome Fortbewegung von Fahrzeugen spielt heutzutage eine immer gr\"o\ss{}ere Rolle. Dazu werden verschiedene Algorithmen, zur Lokalisierung, Kartierung und Pfadverfolgung ben\"otigt. Diese werden auf einer realen Roboter-Platform implementiert und getestet.} 

\section{Einleitung}
	Selbstfahrende Fahrzeuge sind ein gro{\ss}es Thema der Zukunft. Damit diese zuverl\"assig und sicher fahren k\"onnen braucht es gute Algorithmen in verschiedenen Bereichen. Wie gut bestehende Ans\"atze funktionieren und wo deren Schw\"achen sind wird in diesem Paper anhand einer simplen Roboter-Plattform mit Laserscanner untersucht. 

	Zur Lokalisierung in einer zuvor kartierten Umgebung kann der \textit{Adaptive Monte Carlo Localization}-Algorithmus, von Dieter Fox im Paper \textit{KLD-Sampling: Adaptive Particle Filters} \cite{amclPaper} vorgestellt, verwendet werden. 
	
	Die daf\"ur ben\"otigte Karte kann mit dem \textit{SLAM-Gmapping}-Algorithmus von Giorgio Grisetti generiert werden. Der Algorithmus wird im Paper \textit{Improved Techniques for Grid Mapping
	with Rao-Blackwellized Particle Filters} \cite{Gmapping} besprochen. Dieser l\"ost dass Problem der gleichzeitigen Lokalisation und Kartierung durch die Nutzung des Laserscanners schon bei der Lokalisation und nicht erst bei der Kartiertung. 
	
	Mit einer guten Lokalisation ist es m\"oglich einem Pfad zu folgen. Dafür hat Giovanni Indiveri einen Algorithmus, im Paper \textit{SWITCHING
	LINEAR PATH FOLLOWING FOR
	BOUNDED CURVATURE CAR-LIKE
	VEHICLES} \cite{Giovanni} beschrieben, entwickelt. 

	Die drei Algorithmen werden im Abschnitt 2 genauer erkl\"art. Im Abschnitt 3 folgt eine kurze Beschreibung unserer Testplattform und dem verwendeten \textit{Robot Operating System}. Die Test-Ergebnisse werden im Abschnitt 4 vorgestellt und disskutiert.
  

\section{Algorithmen}

\subsection{Lokalisation}
\subsubsection{Odometrie}
{
	Die Odometrie ist eine einfache Möglichkeit der relativen Positionsbestimmung und bildet die Grundlage für anspruchsvollere Algorithmen wie \textit{AMCL}. Dabei wird aus der vorher bekannten Position des Roboters und der vermuteten zur\"uckgelegten Weg-strecke die neue Position berechnet. Die Wegstrecke wird über die Steuerungsbefehle und ein Modell des Roboters berechnet. Da es kein weiteres Feedback über die Position gibt ist dies eine \textit{Open loop}. 
}
\subsubsection{Adaptive Monte Carlo Localization \cite{mclWiki} \cite{amclPaper}} 
{
	Im folgenden als AMCL abgek\"urzt, ist ein Algorithmus der mit Hilfe eines Partikelfilters die Position eines Roboters bestimmt. Dazu wird eine Karte der Umgebung ben\"otigt. Da die Pose zu Beginn nicht bekannt ist, stellt der Roboter Hypothesen dar\"uber auf der Karte an, verteilt also die Partikel \"uber den Zustandsraum. Die anf\"angliche Verteilung auf der Karte kann verschieden sein. Es ist zum Beispiel m\"oglich diese  gleichm\"a{\ss}ig über die ganze Karte zu verteilen. 
	Bei der von den Autoren verwendeten Implementation ist sie Gau{\ss}-verteilt um eine gegebene anf\"angliche Pose, siehe Abbildung ~\ref{fig:initalParticleDistribution}. \begin{figure}[h]
		\includegraphics[width=\linewidth]{pictures/initial_distribution.jpg}
		\caption{Partikelverteilung in Anfangspose \label{fig:initalParticleDistribution}}
	\end{figure}
	\newpage
	Ist der Roboter tatsälich an einem anderen Ort, so hat er keine Chance sich zu lokalisieren. 
	
	Die Hypothesen kann man sich als virtuelle Roboter auf der Karte vorstellen. F\"ahrt der reale Roboter, so fahren auch die virtuellen Roboter, mit den gleichen Steuerungsbefehlen. Die realen Sensorwerte werden mit denen der virtuellen Robotern verglichen. Die virtuellen Roboter gewinnen ihre Sensormesswerte durch die Karte. Als reale Sensormesswerte werden die Messungen des Laserscanners verwendet. 
	
	Je unstimmiger die Daten des virtuellen Roboters sind, desto unwahrscheinlicher ist die Hypothese dass der reale sich dort befindet. Daher werden jene Partikel gel\"oscht. Im Bereich der wahrscheinlichen Hypothesen, werden neue Partikel/Hypothesen erzeugt.
	
\begin{figure}[h]
	\includegraphics[width=\linewidth]{pictures/drive_little.jpg}
	\caption{Partikelverteilung nach kurzer Neuorientrierung durch Bewegung. Man erkennt die Partikel sind konzentrierter}
\end{figure}
		
	Der virtuelle Roboter  mit besten den \"Ubereinstimmungen, ist die beste Estimation der Pose.
	Je n\"aher die wahrscheinliche Hypothesen bei einander liegen, desto sicherer ist der Roboter sich seiner Pose. In diesem Fall kann die Anzahl der Partikel reduziert werden um Ressource zu sparen. Daher das \textit{Adaptive} aus \textit{AMCL}.
}
\newpage
\subsection{Kartierung mit gmapping  \cite{Gmapping}}
{
	Die Lokalisation eines Roboters ben\"otigt eine Karte. Eine unbekannte Umgebung wird dabei mit den Daten eines Laserscanners und den aktuellen Posedaten erfasst und von dem Algorithmus GMapping verarbeitet.
	Die Herausforderung liegt dabei in der gleichzeitigen Lokalisierung und Kartierung, dem \textit{simultaneous localization and mapping} Problem kurz SLAM. Denn beide bedingen sich gegenseitig. Um zum Beispiel zwei Laserscans zu einer Karte zusammenzuf\"ugen, m\"ussen die relativen Posen der Aufnahmen bekannt sein. Also ein Lokalisierungsproblem. Und um sich mit dem Laserscanner zu lokalisieren, ben\"otigt man wiederum Kartendaten. \\

	\textbf{TODO hier weiter schreiben}

	Die Idee des  \textit{Grid}Mappings ist, die ungenauen Sensordaten einer Umgebung, auf einer 2D-Karte in bin\"aren Zufallsvariablen darzustellen. Dabei wird die Karte in Gitter unterteilt, in dem jedes Quadrat mit einer Wahrscheinlichkeit aussagt, ob es belegt ist oder nicht. Die Variablen stellen also Objekte in der Umgebung dar. Algorithmen, wie AMCL, werten die Zufallsvariablen aus. 
	\\ 
	\\

\subsection{Pfadverfolgung mit Giovanni-Controller}


\begin{figure}[h]
	\includegraphics[width=\linewidth]{pictures/Pfadverfolgung.JPG}
	\caption{Modell der Pfadverfolgung}
\end{figure}

	Der nicht-lineare Regler des Giovanni Indiveri und der Maria L. Corradini\cite{Giovanni} wird zur Pfadverfolgung verwendet. Er basiert auf der Arbeit von Canudas de Wit et al. \cite{Canudas} und ist um eine Funktion erweitert, die den  minimalen Wendekreis, wie auch die maximale Geschwindigkeit des Roboters ber\"ucksichtigt. Die Implementierung garantiert nach Lyapunov, f\"ur einen beschr\"ankten, nicht-linearen Pfad, asymptotische Konvergenz und asymptotisch stabile Fehlerdynamik. Schrittweise neue Berechnungen der Reglerparameter f\"uhren zu einer schnelleren Konvergenz. Hierzu verwendet der Algorithmus eine orthogonale Projektion auf den Roboter selbst. Das Modell in Abbildung 5 stellt den abzufahrenden Pfad dar. Dabei ist der Winkel zwischen der x-Achse und der L\"angsachse des Roboters $\theta$ und $\theta_{d}$
beschreibt den Winkel einer Tangente an den Pfad zur 
x-Achse. Die Differenz 
\begin{equation}
\tilde{\theta} = \theta -\theta_{d}
\end{equation}
beschreibt den Winkel der Fahrtrichtung des Roboters und der Tangente an einem Pfadpunkt p. Der Abstand zwischen der orthogonalen Projektion des Roboters auf den Pfad und des Rotationszentrums des Roboters ist gegeben durch l.
Der Pfad wird zur Vereinfachungen in lineare Teilschnitte gen\"ahert, wodurch sich die Gleichungen vereinfachen. Die Formel f\"ur die Winkelgeschwindigkeit $\omega$ mit der linearen Geschwindigkeit u des Roboters


\begin{equation}
\omega=  \frac{u \kappa(s) cos(\tilde{\theta})}{1-l \kappa(s)}-h u l  \frac{sin(\tilde{\theta})}{\tilde{\theta}}-\gamma\tilde{\theta} :h\gamma > 0
\end{equation}\\

vereinfacht sich im linearen Fall $\kappa(s)=0$ zu \\

\begin{equation}
\omega= -h u y  \frac{sin(\theta)}{\theta}-\gamma\theta :h\gamma > 0
\end{equation}\\



	Durch Koordinatentransformation, dient die x-Achse als die Fahrtrichtung des Robotors  und y (der Roboter-Pfad-Abstand) \"ubernimmt die Rolle des l. Der Winkel Theta wird durch das \"ubereinanderlegen zu null.


\section{Test-Plattform}
\subsection{ROS}


F\"ur die Implementierung und Tests der Algorithmen wird das \textit{Robot Operating System}, kurz ROS genutzt. Es ist kein Betriebssystem im eigentlichen Sinn, sondern ein Framework. Es erm\"oglicht Hardware-Abstraktion, Paket-Management und stellt eine Middleware, bereit mit der verschiedene Prozesse kommunizieren k\"onnen. \cite{rosWiki}

\begin{figure}[h]
	\includegraphics[width=\linewidth]{pictures/ROS_basic_concepts.png}
	\caption{Kommunikation zwischen Nodes \label{fig:rosNodes}}
\end{figure}

Die ROS-Software ist in sogenannten Nodes organisiert, welche die eigentlichen Berechnungen durchf\"uhren. Der ROS-Master hilft den Nodes sich zu finden und eine Verbindung aufzubauen. Die Kommunikation zwischen den Nodes erfolgt dann direkt untereinander über ein ROS spezifisches Protokoll dass auf TCP/IP aufsetzt. Nodes k\"onnen auf Topics ver\"offentlichen und diese abonnieren, siehe dazu Abbildung ~\ref{fig:rosNodes}. \cite{rosConcepts}


Durch die Nodes k\"onnen Funktionalit\"aten wie Planung, Pfadverfolgung, Sensorik, etc getrennt werden. Au{\ss}erdem k\"onnen so einfach Nodes anderer Leuten genutzt werden. Dies erm\"oglicht es in kurzer Zeit eine Plattform zum Testen der Algorithmen aufzubauen, und ohne gro{\ss}en Aufwand Algorithmen durch Nodes zu implementieren. ROS-Nodes k\"onnen in C++ oder Python geschrieben werden.

\subsection{Hardware}
 
Zur Verf\"ugung stehen drei Roboter mit Differentialantrieb. Zwei vom Typ Volksbot mit Motor Controller VMC, sowie ein Robotersystem mit dem EPOS2 Motor Controller von \textit{maxon motor control}. Der VMC \cite{Volksbot} wird mittels serieller Schnittstelle mit dem Steuerrechner verbunden. Neben der Motoransteuerung k\"onnen Geschwindigkeit und Strom mittels eines PID-Reglers kontrolliert werden. 
Da sich die Roboter im Aufbau und in der Betriebsweise gleichen, können die Algorithmen auf allen gleich gut getestet werden.

Bei allen verwendeten Robotern ist an der Front ein SICK LMS100 Laserscanner auf einer H\"ohe von etwa 35 cm montiert. Dieser hat einen Arbeitsbereich von 270\degree  und eine Reichweite von bis zu 20 Metern.\cite{lms} 
 
ROS l\"auft auf einem handels\"ublichen Notebook, das auf den Roboter gestellt wird und \"uber LAN und USB mit dem Roboter verbunden ist. 
 

\begin{figure}[h]
	\centering
	{\includegraphics[trim= 2cm 2cm 2cm 2cm, clip=true,width=\linewidth]{pictures/robot.jpg}}
	\caption{\textit{Ute} - Einer der verwendeten Roboter}
\end{figure}


\subsection{Genutzte Nodes}
{
	
	\textbf{TODO bissle was zu den nodes schreiben + das bild fixen.}
	\begin{figure*}[h]
		\includegraphics[trim=9cm 1cm 7cm 1cm , clip= true,width=\textwidth]{pictures/node_graph.png}
		\caption{Vernetzung der \textit{Nodes} im Testaufbau}
	\end{figure*}
	
	
	
	 Die Posedaten publiziert die Odometrie an das ROS Paket gmapping.	
	
	
} 

\section{Test der Algorithmen} 
\subsection{Odometrie und AMCL im Vergleich}


Auf kurzen Distanzen liefert die Odometrie sehr genaue Ergebnisse. Mit wachsender Entfernung nehmen auch Fehler durch zum Beispiel unterschiedliche Dr\"ucke in den Reifen oder eine verst\"arkte Reibung oder Unebenheiten auf anderem Gel\"ande zu. Weitere Fehlerquelle sind h\"oheren Geschwindigkeiten und engeren Kurven, dort neigen die R\"ader zum Durchdrehen und Wegrutschen. Um das zu zeigen wird der Roboter \"ahnliche Pfade in langsamer und schneller Geschwindigkeit abfahren. 	

Es kann passieren, dass AMCL die Anzahl der Partikel so weit verringert das der Zustandsraum nur unzureichend abgedeckt wird. Stimmen die wenigen Hypothesen dann nicht mit der Realit\"at \"uberein, verteilt er die Partikel \"uberall hat eine zu geringe Abdeckung des Zustandsraums und schafft es nicht mehr sich zu lokalisieren.

Probleme oder eine l\"angere Lokalisierungsdauer treten auch auf, wenn eine Umgebung keine markanten Anhangspunkte liefert, ein kreisf\"ormiger Raum mit glatten W\"anden zum Beispiel. 

Um die Lokalisation durch AMCL und Odometrie miteinander zu vergleichen f\"ahrt der Roboter einen "Acht"-f\"ormigen Pfad ab. Die Steuerung erfolgt manuell \"uber einen Joystick und wird zweimal in verschiedenen Geschwindigkeiten durchgef\"uhrt. Ein Problem entsteht am Anfang, da AMCL nur korrekt arbeitet, wenn die Startpose vorher durch den Benutzer auf den Punkt genau gesch\"atzt wird oder durch Bewegung des Roboters spezifiziert wird. Durch die Bewegung verliert aber die Odometrie an Genauigkeit und startet nicht mehr im Ursprung (0/0). Um Genauigkeit zu garantieren, wird ein Algorithmus verwendet, der die Koordinatensysteme nach der Kalibrierung transformiert.

\begin{figure}[h]
	\centering
	\subcaptionbox{Mit einer Geschwindigkeit $\leq$ 0.8m/s}{\includegraphics[width=\linewidth]{pictures/odo_amcl_comparision_slow.jpg}}\par\medskip
	\caption{ Odometrie und AMCL im Vergleich. }
\end{figure}




Im Experiment startet der Roboter im Ursprung und bereits zu Beginn der Durchf\"uhrung kennzeichnet sich ab, dass der Odometriepfad fehlerhaft ist. Bis der Roboter wieder an der Startpose ist, summieren sich die Fehler auf und die Zielpose weicht bis zu 2 m von der Startpose ab. Der AMCL Pfad dagegen, kehrt bis auf wenige Zentimeter zur Startpose zur\"uck. Zus\"atzlich muss in diesem Versuch die menschliche Ungenauigkeit, wie ungenaues Augenma{\ss} und Steuerungsschwierigkeiten, beachtet werden. Aus dem Vergleich ist ersichtlich, dass der Fehler bei AMCL auch in der Distanz, also bei langen Pfaden, nicht gr\"o{\ss}er ist, als er auch bei k\"urzer w\"are, w\"ahrend bei der Odometrie bei langer Laufzeit die Qualit\"at stetig abnimmt.


Nachteil AMCL: benötigt Karte, Pfad kann nicht in unbekannter Umgebung abgefahren werden

Vorteil: Odometrie ist h\"aufiger und schneller verf\"ugbar da der Rechenaufwand geringer ist. 

\begin{figure}[h]
	\centering
	{\includegraphics[width=\linewidth]{pictures/amcl_fail.png}}
	\caption{ Auch AMCL ist nicht perfekt }
\end{figure}




\subsection{Test von Gmapping}
{
	Das Untergeschoss des Informatikinstituts W\"urzburg ist mit einem Frauenhofer-Roboter, der mit einem Sick LMS100 Laserscanner ausgestattet ist, in einer 2D-Karte kartiert.  Um diese Karte korrekt aufzunehmen, werden nur so und soviel Partikel ben\"otigt. Die Aufnahme ist bis auf einen 1 cm genau und zeigt keine signifikanten Fehler. Bewegte Objekte wie Menschen werden erkannt und nicht in der Karte verzeichnet. Dagegen sorgt helles Licht, das durch die Fensterfronten scheint f\"ur eine Ungenauigkeit und kann nicht als klare Begrenzung festgestellt werden. F\"ur klare Linie wie W\"ande ist es wichtig, das Gel\"ande mit einem Geschwindgkeitslimit von 2 km/h (halbe Schrittgeschwindigkeit) abzufahren. 
	
	\begin{figure}[h]
		\centering
		\subcaptionbox{fehlerhafte Karte}{
			\includegraphics[width=0.45\textwidth]{pictures/firstMap.jpeg}}
		\subcaptionbox{korrekte Karte}{
			\includegraphics[width=0.45\textwidth]{pictures/correctMap.JPG}}
		\caption{Karten aufgezeichnet mit Gmapping}
	\end{figure}
	
	
	Deutliche Unterschiede sind in den Karten von Abbildung 4 zu erkennen. Bild (a) zeigt eine Karte, die im ersten Versuch aufgenommen ist und aus Unwissenheit mit zu hoher Geschwindigkeit und nicht oft genug abgefahren ist. Im Vergleich dazu ist die Karte (b) durch langsameres und stetigeres Abfahren detailgetreuer und hat klare Linien.
	
		
}




\subsection{Test und Implementierung von \texttt{gio\_path}}


Zun\"achst wird die Pfadverfolgung simuliert, um zu sehen ob sie \"uberhaupt funktioniert. Der Robotersimulator wird als ROS-Node implementiert und soll vorgebene Pfaddateien abfahren.


\begin{figure}[h]
	\subcaptionbox{Verfolgung eines spiralf\"ormigen Pfades\label{fig:simulatedSpiral}}{
		\includegraphics[width=\linewidth]{pictures/simulated_spirale.jpg}
		
	}
	\subcaptionbox{Verfolgung eines Acht-f\"ormigen Pfades}{
		\includegraphics[width=\linewidth]{pictures/simulated_acht.jpg}}
	\caption{Simulierte Pfadverfolgung}

\end{figure}
Es zeigt sich, dass der Giovanni-Controller nicht immer alle Punkte des Pfades perfekt ansteuert, wie in Abbildung ~\ref{fig:simulatedSpiral} zu erkennen.  


\newpage
Um den \texttt{gio\_path} Algorithmus auf einem realen Roboter zu testen, wird eine ROS-Node verwendet. Diese benutzt  \texttt{gio\_path} um einen realen Roboter zu steuern. Der Algorithmus steuert wie folgt den Roboter: 

\begin{algorithm}
	pathDone $\leftarrow$ false\;
	rightSpeed $\leftarrow$ 0.0\;
	leftSpeed $\leftarrow$ 0.0\;
	controller.setPath(pathFile)\;
	\While{!pathDone}{
		controller.setPose(currentPose)\;
		pathDone = controller.getNextState(leftSpeed, rightSpeed)\;
		publishToMotors(leftSpeed, rightSpeed);
	}
\caption{\textit{Giovanni Controller} Implementation}
\end{algorithm}

Die Autoren entscheiden sich als Testpfad eine 12m lange Spirale zu nutzen. Dieser Pfad wird viermal abgefahren, einmal mit Odometrie als Input f\"ur \textit{Giovanni Controller} und einmal mit \textit{AMCL} als Input, jeweils mit erh\"ohter/ niedriger Geschwindigkeit.

Da die Autoren leider keine M\"oglichkeit haben die Position des Roboters extern zu tracken, wird f\"ur die Analyse der Pfadverfolgung mit Odometrie \textit{AMCL} als "Wahrheit" verwendet.
\newpage
\begin{figure}
	\centering
	\subcaptionbox{niedrige Geschwindigkeit $\approx$ 0,714m/s \label{fig:odoLowSpeed}}{
		\includegraphics[width=0.45\textwidth]{pictures/path_odometry_slow.jpg}}
	\subcaptionbox{erh\"ohte Geschwindigkeit $\approx$ 3.2 m/s\label{fig:odoHighSpeed}}{
		\includegraphics[width=0.45\textwidth]{pictures/path_odometry_fast.jpg}}
	\caption{Pfadverfolgung mit Odometrie}
\end{figure}

Zu beobachten ist, dass die Pfadverfolgung mit Odometrie bei geringer Geschindigkeit ($\approx$ 0,714 m/s ) mit weniger als $\approx$ 30cm Abweichung funktioniert. Siehe dazu Abbildung ~\ref{fig:odoLowSpeed}. Die Abbweichung kommt dabei einerseits durch den \textit{Giovanni Controller} zustande, was man auch bei der Simulation sehen kann. Außerdem macht die Odometrie Fehler. Man erkennt zum Beispiel dass der Roboter am Ende des Pfades etwa 30 cm zu wenig weit f\"ahrt.
Bei einer erhöhten Geschwindigkeit von $\approx$ 3.2 m/s fährt der Roboter deutlich schlechter siehte Abbildung \ref{fig:odoHighSpeed}. Dies liegt vermutlich daran dass die R\"ader, des Roboters vor allem in Kurven durch drehen.   

\newpage  

\begin{figure}[h]
	\centering
	\subcaptionbox{niedrige Geschwindigkeit $\approx$ 0,714m/s}{
		\includegraphics[width=0.45\textwidth]{pictures/path_amcl_slow.jpg}}
	\subcaptionbox{erh\"ohte Geschwindigkeit  $\approx$ 3.2 m/s}{
		\includegraphics[width=0.45\textwidth]{pictures/path_amcl_fast.jpg}}
	\caption{Pfadverfolgung mit AMCL}
\end{figure}

Da bei \textit{AMCL} nicht \textit{AMCL} selbst als absolute Referenz verwendet werden kann, wird bei AMCL der Pfad zum Ausgangspunkt zur\"uck verl\"angert. In dem die Startposition auf dem Boden markiert wird, erkennt man die Pr\"azession mit der Roboter beziehungsweise der Algorithmus arbeitet.
Bei beiden Geschwindigkeiten ist erreicht der Roboter eine Genauigkeit von unter 20 cm. Der schneller abgefahrene Pfad weist geometrisch gr\"o{\ss}ere Abweichungen zum vorgegebenen Pfad auf, als der langsam Abgefahrene. 
Dies liegt vermutlich daran, dass die Sample-Time von AMCL bei der erh\"ohten Geschwindigkeit  von $\approx$ 3.2 m/s nicht mehr ausreicht und so Abweichungen auftereten, bevor der Controller diese korregieren kann. 

\section{Zusammenfassung und Ausblick}


Dieses Paper pr\"asentiert den Vergleich zwischen AMCL und Odometrie. Die anfangs formulierten Ziele wurden erf\"ullt. Mit dem ROS Package kann der Roboter \"uber Eingabesysteme gesteuert werden. Mittels \textit{GMapping} ist die Erstellung einer 2D-Karte m\"oglich. Nach Belieben kann der Roboter sich mit AMCL-Daten oder Odometriedaten lokalisieren. 

In verschiedenen Vorg\"angen wurden die Algorithmen und Systeme getestet und haben keine \"uberraschenden Ergebnisse geliefert. 
Der Roboter selbst\"andig mittels Pfadverfolgung eine gegebene Punktewolke ab. Die angegebene Punkte werden pr\"azise abgefahren, je dichter der Pfad in Punkten ausgedr\"uckt ist, desto genauer wird der Pfad verfolgt. Daraus l\"asst sich schließen, dass der Algorithmus des Giovanni Indiverdi korrekt funktioniert.
\\
\\
Lokalisierungsschwierigkeiten zeigen sich in bei lautem Rauschen, zum Beispiel in Computerr\"aumen oder in R\"aumen ohne markante Anhaltspunkte. Bewegte Hindernisse wie Menschen werden zwar vom Laser erfasst, stellen aber bei der Kartierung keine Probleme dar und werden nicht in der Darstellung ber\"ucksichtigt. 
\\
\\
F\"ur die Zukunft kann die Odometriebestimmung verbessert werden, zum Beispiel durch Angabe pr\"azisere Reifengr\"o{\ss}en und Achsenl\"ange.
\\
Neuronale Netze erm\"oglichen durch pr\"azise Trainingsdaten einen Roboter auf verschiedene Situation vorzubereiten.


\section{Danksagung}
Die Autoren danken dem HiWi Angel f\"ur die Unterst\"utzung und Hilfe bei verschiedenen Problemen mit dem Roboter und \textit{Robot Operating System}.

\newpage
{%\small                   % use small if you need it
	\bibliographystyle{plain}
	\bibliography{paper.bib}       % use a bib-file paper.bib to collect

}
\end{document}








